{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='https://ai.meng.duke.edu'> = <img align=\"left\" style=\"padding-top:10px;\" src=https://storage.googleapis.com/aipi_datasets/Duke-AIPI-Logo.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Household enegy prediction for utility load forecasting\n",
    "\n",
    "_Version 1.0_  \n",
    "_Author(s): Jon Reifschneider, Duke University Pratt School of Engineering_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" style=\"padding-top:10px;\" src=\"smart_meter.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image source: Portland General Electric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _About this teaching case_\n",
    "**Level:** Intermediate  \n",
    "**Language:** Python  \n",
    "**Libraries:** pandas, matplotlib, scikit learn  \n",
    "**Industry:** Energy\n",
    "\n",
    "**Learning Topics:**  \n",
    "- Time Series\n",
    "- Exploratory Data Analysis\n",
    "- Feature Engineering & Feature Selection\n",
    "- Supervised Learning Model Selection\n",
    "- Hyperparameter Tuning\n",
    "\n",
    "**Learning Objectives**   \n",
    "- Learn strategies for feature engineering and creation with time series data\n",
    "- Build skills in exploratory data analysis using visual and statistical analysis techniques\n",
    "- Learn how to apply the different methods of feature selection\n",
    "- Build experience in supervised model selection, tuning and validation/testing\n",
    "\n",
    "**Pre-requisites**  \n",
    "- Basic proficiency in Python and pandas\n",
    "- Familiarity with the theoretical foundations of supervised machine learning algorithms\n",
    "\n",
    "**Case Structure**  \n",
    "This teaching case is structured to follow the ***Modified CRISP-DM Data Science Process*** used in Duke University's AI for Product Innovation graduate programs. \n",
    "\n",
    "**Datasets Used**  \n",
    "Makonin, S., Ellert, B., BajiÄ‡, I. et al. Electricity, water, and natural gas consumption of a residential house in Canada from 2012 to 2014. Sci Data 3, 160037 (2016). https://doi.org/10.1038/sdata.2016.37\n",
    "\n",
    "Data has been adapted from the original dataset for purposes of this learning activity. The original dataset can be accessed from https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/FIE0S4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "[1: Business Understanding](#1)  \n",
    "[2: Data Understanding](#2)  \n",
    "[3: Prepare Data](#3)  \n",
    "[4: Modeling](#4)  \n",
    "[5: Evaluation & Interpretation](#5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this before any other code cell\n",
    "# This downloads the csv data files into the same directory where you have saved this notebook\n",
    "\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import os\n",
    "path = Path()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Dictionary of file names and download links\n",
    "files = {'Electricity_simple.csv':'https://storage.googleapis.com/aipi_datasets/Electricity_simple.csv',\n",
    "        'Weather_simple.csv': 'https://storage.googleapis.com/aipi_datasets/Weather_simple.csv'}\n",
    "\n",
    "# Download each file\n",
    "for key,value in files.items():\n",
    "    filename = path/key\n",
    "    url = value\n",
    "    # If the file does not already exist in the directory, download it\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url,filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Business Understanding <a class=\"anchor\" id=\"1\"></a>\n",
    "\n",
    "You are working as an analyst for the Canadian electic utility BC Hydro, which serves 1.8 million customers in British Columbia.  You have been asked to work on the utility's load forecasting model for predicting future energy demand.  Accurate demand prediction is critical for the utility to produce sufficient power to meet demand on a short-term and long-term basis.  \n",
    "\n",
    "The expansion of smart meter usage among many utilities has created increasing interest in machine learning models which predict energy demand at the individual home or building level, which can then be aggregated to a utility's entire territory.  You have been asked to explore this approach using your organization's smart meter data.  A review of advantages and limitations of different machine learning based approaches can be found <a href='https://www.informs-sim.org/wsc15papers/396.pdf'> here</a>.\n",
    "\n",
    "In particular, you have been asked to better understand the relationship between changing weather conditions and the electric demand for a household. Your first objective is to examine the relationships between various weather parameters and electric consumption and determine which weather parameters most influence a home's energy usage.  Once you have understood these relationships, you have been asked to evaluate different machine learning approaches to modeling a home's energy usage and report back to your team on what features are most valuable to use in prediction, which modeling approach(es) have shown most promise, and how well you are able to predict load at an individual home level.  You will use root mean squared error (RMSE) as the evaluation metric for your modeling work.\n",
    "\n",
    "If your work ultimately leads to an improvement upon your organization's load forecasting capability, it can result in significant operational savings.  Overforecasting of power demand leads to greater production of power than needed, which must then either be stored or sold. In times when demand is high, overforecasting can also lead to the unnecessary use of expensive peaker plants to produce extra power.  On the other hand, underforecasting can have significant consequences as the utility must purchase additional power, employ demand response measures to curtail demand, or in the worst case enforce rolling blackouts.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Understanding <a class=\"anchor\" id=\"2\"></a>\n",
    "\n",
    "To assist you with your analysis, you have been provided a dataset containing energy usage per minute for a home in the Vancouver area for the time period April 1 2012 through March 30 2014. The dataset contains the energy consumption in Watts for each minute over the time period.  You have also received a separate dataset of weather information, which contains weather parameters for the local area of the home on an hourly basis over the time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "### LOAD ADDITIONAL LIBRARIES AS NEEDED\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's import the energy consumption data and convert the index to a time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import electricity data\n",
    "raw_data = pd.read_csv(\"Electricity_simple.csv\")\n",
    "energy_data = raw_data.copy()\n",
    "\n",
    "# Convert index to timeseries\n",
    "energy_data.index = pd.to_datetime(energy_data['UNIX_TS'],unit='s').values\n",
    "energy_data = energy_data.drop(labels='UNIX_TS',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for anomalous values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot your data to visually check for potential outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with sensor data, we occasionally have null values due to problems with power or communications.  Sometimes these are recorded as null values, and other times a value of 0 is reported.  If we look closely at the plot we generated above, there appear to be a few instances where the consumption is reported as 0.\n",
    "\n",
    "Filter the data to check for any instances where the 'Consumption' value is 0.  If there are 0 values, forward-fill them from the last previously recorded energy usage value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "    \n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample the energy consumption to hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our energy consumption data has been collected every minute over the time period. For purposes of modeling, aggregate the data to an hourly frequency.  Then, visualize the energy consumption by hour of the day to understand the usage pattern throughout a normal day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add in weather data\n",
    "Now, add in weather data to your dataframe.  The hypothesis you have been asked to explore is that weather conditions impact energy usage, and so you expect that a model which includes weather parameters will perform better than one which accounts only for the time-dependent fluctuations in consumption over the course of a day.\n",
    "\n",
    "Read in the weather data from 'Weather_simple.csv', add it to your dataframe and convert any categorical variables into numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see if there are any null values in the dataset.  If there are null values, replace them using a forward-fill approach (fill null values using the last previous reported value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually analyze the relationships between Consumption and the weather parameters you have available, and explain the relationships you can visually identify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Prepare Data <a class=\"anchor\" id=\"3\"></a>\n",
    "## Feature Engineering & Feature Selection\n",
    "### Add time series features\n",
    "Create new features which may help explain the variation of consumption over time due to seasonality.  Add these features into your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually analyze your new features and comment on whether you would expect them to have value in modeling the consumption over time, based on your visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate feature selection  \n",
    "First, you should create a subset of the data to use for feature selection which includes only the training data.  We do not use our test data set for feature selection so it does not influence our choice of features to use for modeling.  We will train our model on the data from the period April 2012 - February 2014.  We will then use our trained model to predict the energy consumption for each hour in the month of March 2014 as a test set to evaluate our model performance.  Below, create a subset to use for feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continuous variables**  \n",
    "Perform univariate feature selection on your continuous variables, selecting an appropriate statistical test, to identify any features which are duplicative or unnecessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorical variables**.  \n",
    "Perform univariate feature selection on your categorical variables, selecting an appropriate statistical test, to identify any features which are duplicative or unnecessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop unnecessary features**  \n",
    "Any features which you have identified as being duplicative or clearly unnecessary in our univariate feature selection tests you can now drop to simplify our dataset.  Based on your univariate feature selection tests, which variables have you determined can be dropped from our dataset? Go ahead and drop them now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add polynomial terms for continuous features**  \n",
    "As we could see in the scatterplots above, the relationship between Consumption and some of our continuous variables may not be linear.  To better model these relationships, we can add polynomial terms as new features.  Do this below, before you conduct your final round of feature selection, so you can include and evaluate these quadratic features and interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedded feature selection using Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Random Forest Feature Importance model from scikit learn to evaluate the importance of each feature in your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the results from your feature importance model, determine which features you would like to keep and drop the features that do not have value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode your categorical variables to prepare them for modeling, using an encoding method of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Modeling <a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define validation/test approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you begin training and evaluating models, you need to determine our approach for validation and testing. Earlier we determined that we will use the data from March 2014 as our test set.  We will use the remainder for training.  \n",
    "\n",
    "However, to evaluate and compare different modeling approaches you also should define a validation set strategy.  Because we are working with time series data, normal cross-validation is not a good strategy since consumption values which are closer in time are likely to be similar.  Thus, we can either create hold-out validation sets or we can use scikit learn's TimeSeriesSplit which creates successive training sets as supersets of those that come before them. Since you are going to perform algorithm selection as well as hyperparameter tuning, the preferred approach would be to use nested validation or nested cross-validation.  \n",
    "\n",
    "Using a nested cross-validation approach, you will use an inner cross-validation loop to perform hyperparameter optimization of each algorithm.  You will then use an outer cross-validation loop compare the prediction ability of the optimized model from each algorithm and select the algorithm that performs best.  Finally, you will re-do the hyperparameter tuning using the full training plus validation data, and use the test set to evaluate the perfomance of your final optimized model. \n",
    "\n",
    "Begin by splitting data into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish a baseline for performance\n",
    "It is usually a good idea to start with a simple model and evaluate its performance to establish a baseline.  Then, you can proceed with more advanced model selection methods and hyperparameter tuning and easily determine how much they improve your performance relative to your simple baseline.\n",
    "\n",
    "Train a linear regression model on your training set and then calculate the RMSE of your baseline model on your test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to train and evaluate models on the data. Determine which algorithms you would like to evaluate.  Then use a time series specific nested cross-validation approach to optimize models for each algorithm and compare your optimized models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning on selected model  \n",
    "Based on the results of your above model selection, determine the algorithm you will use.  Then, use the entire training dataset to tune and train your model. Start by tuning your model's hyperparameters to optimize it.  Consider your choice of validation strategy for the tuning - either a hold-out validation set or a time series cross validation approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Evaluation & Interpretation <a class=\"anchor\" id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now use your optimized model to generate predictions on your test set to calculate the test set RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, plot a residual plot of your model predictions to help diagnose any potential issues with your model.  For a high-quality model, the residuals should be small and randomly distributed around the centerline.  Patterns in our residual plot mean our model is unable to capture some of the explanatory information. We can also use the residual plot as another check for the existance of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, for the test period plot the predicted consumption values and the actual consumption values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your feature selection and model, what have you discovered about the key drivers of energy consumption for this household?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your final model performance and your visual analyses of the predictions and residuals, what insights can you derive about your model? Does it do a reasonable job in predicting future energy consumption at the household level? What might you do to further improve it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your utility organization were to design a new load forecasting system for their whole network using a bottom-up approach based on your individual household model, what challenges might you foresee?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
